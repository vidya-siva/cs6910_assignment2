# -*- coding: utf-8 -*-
"""assignment2_partB_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bFKf4cjHT0EoXD-2Z_7SgleythTpac5W
"""


import tensorflow as tf
import numpy as np
import wandb
import os,sys
# %tensorflow_version 2.x
import tensorflow as tf
import timeit
from tensorflow.keras.applications.resnet50 import ResNet50
from keras.applications.inception_resnet_v2 import InceptionResNetV2
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import Dense,Dropout,Input,Flatten,MaxPooling2D,BatchNormalization
from wandb.keras import WandbCallback
sys.path.append(os.path.dirname(os.getcwd()))
from warmUp import *



# Commented out IPython magic to ensure Python compatibility.

# GPU test


# We run this to warm up; see: https://stackoverflow.com/a/45067900

cpu()
gpu()

# Run the op several times.
print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '
      '(batch x height x width x channel). Sum of ten runs.')
print('CPU (s):')
cpu_time = timeit.timeit('cpu()', number=10, setup="from __main__ import cpu")
print(cpu_time)
print('GPU (s):')
gpu_time = timeit.timeit('gpu()', number=10, setup="from __main__ import gpu")
print(gpu_time)
print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))



# train and test directory locations
path = os.path.dirname(os.getcwd())
print(path)
train_dir =path + "/inaturalist_12K/train"
val_dir = path + "/inaturalist_12K/val"

isSweep = False

wandb.login()

# isSweep = True 

# sweepMethod ='bayes' #['grid','bayes','random']

# if isSweep:

#   sweepConfig = {'name': sweepMethod + '-PartB-fine-tuning-sweep',
#                 'method': sweepMethod,
#                 'metric' : {'name': 'val_acc', 
#                             'goal': 'maximize'}
#                 }

#   parameters = {
      
#       'modelName'  : {'values': ['ResNet50','InceptionV3','Xception','InceptionResNetV2']},
#       'denseSize'  : {'values': [64,128]},
#       'num_epochs' : {'values': [4,8]},
#       'dropOut'    : {'values': [0.2,0.4]},
#       'batchNorm'  : {'values': [0,1]},
#       'isDataAug'  : {'values': [0,1]},
#       'optimizer'  : {'values': ['adam']},
#   }

#   sweepConfig['parameters'] = parameters
#   sweepID = wandb.sweep(sweepConfig, project="cs6910_assignment2", entity="cs6910_assignment")

def createDataset(imgHeight,imgWidth,isDataAug):

  imgSize = (imgHeight, imgWidth) 
  batchSize = 32
  if isDataAug:
    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
                    rescale=1./255,
                    validation_split = 0.2,
                    shear_range=0.2,
                    zoom_range=0.2,
                    featurewise_center=False,  # set input mean to 0 over the dataset
                    samplewise_center=False,  # set each sample mean to 0
                    featurewise_std_normalization=False,  # divide inputs by std of the dataset
                    samplewise_std_normalization=False,  # divide each input by its std
                    zca_whitening=False,  # apply ZCA whitening
                    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)
                    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
                    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
                    horizontal_flip=True,  # randomly flip images
                    vertical_flip=False
                    )

    train_data = train_datagen.flow_from_directory(
            train_dir,
            subset='training',
            target_size=imgSize,
            batch_size=batchSize,
            class_mode='categorical',
            shuffle = True,
            seed = 123)

    val_data  = train_datagen.flow_from_directory(
            train_dir,
            subset='validation',
            target_size=imgSize,
            batch_size=batchSize,
            class_mode='categorical',
            shuffle = True,
            seed = 123)
    
  else:
    train_data = tf.keras.utils.image_dataset_from_directory(
                          directory = train_dir,
                          labels = 'inferred',  
                          label_mode = 'categorical',
                          color_mode = 'rgb',
                          batch_size = batchSize,
                          image_size = imgSize,
                          shuffle = True,
                          seed = 5,
                          validation_split = 0.2,
                          subset = 'training')

    val_data = tf.keras.utils.image_dataset_from_directory(
                          directory = train_dir,
                          labels = 'inferred',  
                          label_mode = 'categorical',
                          color_mode = 'rgb',
                          batch_size = batchSize,
                          image_size = imgSize,
                          shuffle = True,
                          seed = 5,
                          validation_split = 0.2,
                          subset = 'validation')


    # Retaining 25 percent of train and validation data and discarding the rest
    len_train, len_val = len(train_data), len(val_data)
    train_data = train_data.take(int(0.25*len_train))
    val_data = val_data.take(int(0.25*len_val))

  return train_data , val_data

def train(config=False):
  # with wandb.init(config=config):
  with tf.device('/device:GPU:0'):

    #Dynamic values for sweeping
    #Hardcoded for testing 
    denseSize = 64
    optimizer = 'adam'
    num_epochs = 50
    isDataAug = 1
    batchNorm=1 
    dropOut =0.4
    modelName = 'Xception'

    if isSweep:
      config = sweepConfig
      if config:
        print("Running the Model with the dynamic parameters ")
        print(config)
        wandb.init(config=config)
        config = wandb.init().config
        wandb.run.name = 'model_{}_epochs_{}_denseSize_{}_dropOut_{}_batchNorm_{}_isDataAug_{}_Optimizer_{}'\
                          .format(config.modelName, config.num_epochs, config.denseSize, config.dropOut, config.batchNorm, config.isDataAug, config.optimizer)
        modelName  = config.modelName
        denseSize  = config.denseSize
        num_epochs = config.num_epochs
        dropOut    = config.dropOut
        batchNorm  = config.batchNorm
        isDataAug  = config.isDataAug
        optimizer  = config.optimizer


    if(modelName == "ResNet50"):
      imgHeight = 224
      imgWidth  = 224

      base_model = ResNet50(
        weights = 'imagenet', # loading the weights, pre trained on ImageNet
        input_shape = (imgHeight,imgWidth,3),
        include_top = False # Dense layers of the model are not included at the top
        )

    elif(modelName == "InceptionV3"):
      imgHeight = 299
      imgWidth  = 299

      base_model = InceptionV3(
        weights = 'imagenet', # loading the weights, pre trained on ImageNet
        input_shape = (imgHeight,imgWidth,3),
        include_top = False # Dense layers of the model are not included at the top
        )

    elif(modelName == "Xception"):
      imgHeight = 299
      imgWidth  = 299

      base_model = Xception(
        weights = 'imagenet', # loading the weights, pre trained on ImageNet
        input_shape = (imgHeight,imgWidth,3),
        include_top = False # Dense layers of the model are not included at the top
        )

    elif(modelName == "InceptionResNetV2"):
      imgHeight = 299
      imgWidth  = 299

      base_model = InceptionResNetV2(
        weights = 'imagenet', # loading the weights, pre trained on ImageNet
        input_shape = (imgHeight,imgWidth,3),
        include_top = False # Dense layers of the model are not included at the top
        )

      
    train_data , val_data = createDataset(imgHeight,imgWidth,isDataAug) 

    for layers in base_model.layers:
      layers.trainable = False

    model = tf.keras.Sequential([
      tf.keras.Input(shape=(imgHeight,imgWidth,3,)),
      base_model,
      Flatten(),
      Dense(denseSize,activation='relu'),
      ])
      
    if batchNorm == 1:
      model.add(BatchNormalization())

    model.add(Dropout(dropOut))
    model.add(Dense(denseSize, activation='relu'))
    model.add(Dropout(dropOut))
    model.add(Dense(10 ,activation='softmax'))

    model.compile(
        optimizer = optimizer,  
        # Loss function to minimize
        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),#'categorical_crossentropy',
        # List of metrics to monitor
        metrics=['accuracy'],
        )

    hist = model.fit(
        train_data,
        epochs=num_epochs,
        validation_data=val_data,
        callbacks = [wandb.keras.WandbCallback()]
        )

# isSweep=False
if isSweep:
  wandb.agent(sweepID, function=train)
else:
  train()



