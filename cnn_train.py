# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18UNtFpiHL84_eQBdNjBynn5kTtK2AoYr
"""

from google.colab import drive
drive.mount('/content/drive')

from numpy import unique, argmax
from tensorflow.keras.datasets.mnist import load_data
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D 
from tensorflow.keras.layers import MaxPool2D
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Activation
from tensorflow.keras.utils import plot_model
from matplotlib import pyplot
import matplotlib.pyplot as plt
import numpy as np
import cv2 
import os
import random
import pickle

#os.chdir("/content/drive/")
#!ls

DATADIR = "/content/drive/MyDrive/inaturalist_12K/train"
Categories = ['Amphibia','Animalia','Arachnida','Aves','Fungi','Insecta','Mammalia','Mollusca','Plantae','Reptilia']

training_data = []
img_size = 100

def create_training_data():

  exceptCount = 0;
  for cat in Categories:
    path = os.path.join(DATADIR,cat)
    class_num = Categories.index(cat)

    for img in os.listdir(path):
      #image = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)

      try:
        image = cv2.imread(os.path.join(path,img)) # reading Color image
        image_resized = cv2.resize(image, (img_size,img_size))
        training_data.append([image_resized,class_num])
      except:
        exceptCount += 1

      
create_training_data()

# Random shuffling of data
random.shuffle(training_data)

#for sample in training_data[:10]:
#  print(sample[1])

features = []
labels   = []

for x,y in training_data:
  features.append(x)
  labels.append(y)

features = np.array(features).reshape(-1,img_size,img_size,3)


pickle_out = open("/content/drive/MyDrive/inaturalist_12K/features.pickle","wb")
pickle.dump(features,pickle_out)
pickle_out.close()

pickle_out = open("/content/drive/MyDrive/inaturalist_12K/labels.pickle","wb")
pickle.dump(labels,pickle_out)
pickle_out.close()


'''

Work in progress

'''








#loading the MNIST dataset
(x_train,y_train),(x_test,y_test) = load_data()

#reshaping the training and testing data
x_train = x_train.reshape((x_train.shape[0],x_train.shape[1],x_train.shape[2],1))
x_test  = x_test.reshape((x_test.shape[0],x_test.shape[1],x_test.shape[2],1))

# normalizing the values of pixels of images
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

#ploting the images
fig = plt.figure(figsize=(5,3))
for i in range(15):
  ax = fig.add_subplot(2,10,i+1,xticks=[],yticks=[])
  ax.imshow(np.squeeze(x_train[i]),cmap = 'gray')
  ax.set_title(y_train[i])

#determine the shape of the input image
img_shape = x_train.shape[1:]
print(img_shape)

#Defining the model
model = Sequential()
# 32 indicates num of filters and (3,3) is the size of the filters


for i in range(3):
  model.add(Conv2D(32, (3, 3), input_shape=img_shape))
  model.add(Activation('relu'))
  # flatten the vector to 2 X 2
  model.add(MaxPool2D(pool_size=(2, 2)))


#dense layer
model.add(Dense(500,activation='relu'))

#output layer
model.add(Dense(10,activation='softmax'))

# model.summary()





plot_model(model,'model.jpg',show_shapes=True)

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])
x=model.fit(x_train,y_trian,epochs=10,batch_size=128,verbose=2,validation_split=0.1)

loss,accuracy = model.evaluate(x_test,y_test,verbose=0)
print(f'Accuracy:{accuracy*100}')

image=x_train[10]
plt.imshow(np.squeeze(image),cmap='gray')
plt.show()

image = image.reshape(1,image.shape[0],image.shape[1],image.shape[2])
p = model.predict([image])
print('Predicted: {}'.format(argmax(p)))

