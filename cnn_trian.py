# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18UNtFpiHL84_eQBdNjBynn5kTtK2AoYr
"""

# use this code if you are using google colab
# from google.colab import drive
# drive.mount('/content/drive')


# %tensorflow_version 2.x
from numpy import unique, argmax
from tensorflow.keras.datasets.mnist import load_data
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, Activation
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers.experimental.preprocessing import Rescaling
from tensorflow.keras import layers
import tensorflow as tf
from matplotlib import pyplot
import matplotlib.pyplot as plt
import numpy as np
import timeit
import cv2 
import os
import random
import pickle
from PIL import Image


device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  print(
      '\n\nThis error states that this notebook is not '
      'configured to use a GPU. Change this in the notebook Settings via the Runtime type or  '
      'command palette (cmd/ctrl-shift-P) or the Edit menu .\n\n')
  raise SystemError('GPU device not found')


# Code to check the cpu and gpu speeds 
# def cpu():
#   with tf.device('/cpu:0'):
#     ranImg = tf.random.normal((100, 100, 100, 3))
#     nett = tf.keras.layers.Conv2D(32, 7)(ranImg)
#     return tf.math.reduce_sum(nett)

# def gpu():
#   with tf.device('/device:GPU:0'):
#     ranImg = tf.random.normal((100, 100, 100, 3))
#     nett = tf.keras.layers.Conv2D(32, 7)(ranImg)
#     return tf.math.reduce_sum(nett)

# # We run each op once to warm up; see: https://stackoverflow.com/a/45067900
# cpu()
# gpu()

# # Run the op several times.
# print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '
#       '(batch x height x width x channel). Sum of ten runs.')
# print('CPU (s):')
# cpu_time = timeit.timeit('cpu()', number=10, setup="from __main__ import cpu")
# print(cpu_time)
# print('GPU (s):')
# gpu_time = timeit.timeit('gpu()', number=10, setup="from __main__ import gpu")
# print(gpu_time)
# print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))

path = os.getcwd()
print(path)
train_dir =path + "/inaturalist_12K/train"
val_dir = path + "/inaturalist_12K/val"

trainIt = tf.keras.preprocessing.image_dataset_from_directory(
                      directory = train_dir,
                      labels = 'inferred',  
                      label_mode = 'categorical',
                      color_mode = 'rgb',
                      batch_size = 32,
                      image_size = (256, 256),
                      shuffle = True,
                      seed = 17,
                      validation_split = 0.2,
                      subset = 'training')

valIt = tf.keras.preprocessing.image_dataset_from_directory(
                      directory = val_dir,
                      labels = 'inferred',  
                      label_mode = 'categorical',
                      color_mode = 'rgb',
                      batch_size = 32,
                      image_size = (256, 256),
                      shuffle = True,
                      seed = 17,
                      validation_split = 0.2,
                      subset = 'validation')

# Retaining 25 percent of train and validation data and discarding the rest
train_data = trainIt.take(int(0.25*len(trainIt)))
val_data = valIt.take(int(0.25*len(valIt)))

print('Train data and Val Data has been set, Now lets use GPU and Define our Model')

def train():
  with tf.device('/device:GPU:0'):

    # Used this in out previous trails of framing the model, Commeting them for the future    
    # inputs = tf.keras.Input(shape = (256, 256, 3))
    # x = Rescaling(scale = 1.0/255)(inputs)

    fOrg = 0.5
    firstLayerFliterCount = 64
    conv_layers = 5
    activation = 'relu'
    denseSize = 32
    optimizer = 'adam'
    num_epochs = 50
    filterSize = [int(firstLayerFliterCount*(fOrg**layer_num)) for layer_num in range(conv_layers)]
    kernelSize = 3

    #Defining Model Architecture

    model = Sequential()

    # Apply some convolution and pooling layers
    for layer_num in range(conv_layers):
        model.add(Conv2D(filterSize[layer_num], (kernelSize, kernelSize), input_shape=(256,256,3)))
        model.add(Activation(activation))
        model.add(MaxPool2D(pool_size=(2, 2)))           


    #dense layer
    model.add(Flatten())
    model.add(Dense(denseSize,activation=activation))

    #output layer
    model.add(Dense(10,activation='softmax'))

    print(model.summary())

    model.compile(optimizer=optimizer,
                  loss = tf.keras.losses.CategoricalCrossentropy(name = 'loss'),
                  metrics = [tf.keras.metrics.CategoricalAccuracy(name = 'acc')])
    model_hist = model.fit(train_data, epochs = num_epochs,validation_data = val_data)


train()

#Trained successfully)

